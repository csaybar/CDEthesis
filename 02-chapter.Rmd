---
output:
  bookdown::html_document2: default
  bookdown::pdf_document2:
    template: templates/brief_template.tex
    citation_package: biblatex
  bookdown::word_document2: default
documentclass: book
#bibliography: [bibliography/references.bib, bibliography/additional-references.bib]
---

```{block type='savequote', quote_author='(ref:lesly02)', include=knitr::is_latex_output()}
What am I in the eyes of most people - a nonentity, an eccentric or an unpleasant person - somebody who has no position in society and never will have, in short, the lowest of the low. All right, then - even if that were absolutely true, then I should one day like to show by my work what such an eccentric, such a nobody, has in his heart.
```
(ref:lesly02) --- Vincent Van Gogh - 1882

# Uncertainty estimation
\minitoc <!-- this will include a mini table of contents-->

## Introduction

Cloud masking is an essential pre-processing for any application of optical remote sensing imagery. Various coarse-resolution cloud cover datasets (\cite{sassen2008classifying, winker2010calipso, Wilson2016}) estimate the worldwide multi-annual cloud occurrence percentage to be around 0.6 ± 0.2, with hotspots in tropical and subtropical forests. Assuming these products are indicative of Sentinel-2 cloud conditions, we can anticipate that more than half of the pixels will need to be removed, i.e. masked out, in order to avoid distortions in further analyses. Given that cloud masking can be interpreted as a statistical classification problem, the confusion matrix can be used to distinguish between two distinct types of errors. On the one hand, cloud omission errors (cloud as non-cloud) can lead to inconsistencies in time series of surface reflectance pixels, whereas cloud commission (clear as non-cloud) reduces the number of valid observations and, as a result, the frequency of cloud-free data (\cite{skakun2022cloud}). Cloud masking techniques are aimed to have a balance between commission and omission errors. Over the last three decades, a plethora of cloud masking methods have been presented (\cite{Hagolle2017, Domnich2021, Louis2016, Qiu2019, richter2019atmospheric, jan_wevers_2021_5788067, Lopez-Puigdollers2021, frantz2019force}). These methods can be classified into two main categories: knowledge-driven (KD) and data-driven (DD). While KD emphasizes the use of physical rules formulated on spectral and contextual features, DD is subjected to the exigency of large pixel-level annotation and costly computational requirements to distinguish cloud versus non-cloud regions.

Only a few studies have attempted to compare the various Sentinel-2 cloud masking methods. For instance, \cite{Cilli} compare DD with KD methods by analyzing 135 Sentinel-2 images distributed worldwide. They concluded that DD methods outperform KD methods. According to their experiments, $10^{4}$ manually labeled pixels are sufficient for train machine learning algorithms to operate accurately cloud masking. Nonetheless, it is well established that DD models are highly dependent on the training dataset (\cite{Lopez-Puigdollers2021}. As a result, the comparison could be unfair, especially if the KD methods have not been as well calibrated to the dataset. \cite{Zekoll2021} compare three KD threshold-based: FMask, ATCOR, and Sen2Cor using a sample-based dataset. The results show that Sen2Cor outperforms the other methods. However, human-made datasets, especially those created by sampling, can be positively skewed if we consider that humans tend to overlook unpleasant information such as cloud borders (ostrich-effect, \cite{Valdez2017}). Using four different datasets, the Cloud Mask Intercomparison eXercise (CMIX) recently compared ten cloud detection algorithms. They suggested that no single algorithm performed better than the others \cite{Skakun2022}. Similar conclusions are found in \cite{tarrio2020comparison} by analyzing 28 images over six Sentinel-2 tiles in Africa and Europe.

In this chapter, we propose to use a novel approach for exploiting the hand-crafted cloud and cloud shadow masking information freely available in cloudSEN12. Unlike previous studies, we intend not only to characterize but also to predict cloud masking uncertainty worldwide. Inspired by deep kernel learning \cite{wilson2016deep}, we explore the use of Gradient boosting Gaussian Processes (GBGP) which combines the structural properties of machine learning architectures with the non-parametric flexibility of kernel methods.

## Data

The basis for Cmask is to predict what the reflectance would be for individual pixels in a Landsat 8 image if cirrus clouds were not present at the time the observations were collected. The basis for those pre- dictions is past observations and the atmospheric conditions, i.e. the water vapor content, at the time of image acquisition. Therefore, two major inputs were included in this analysis: Integrated Water Vapor (IWV) provided by the second Modern-Era Retrospective analysis for Research and Applications (MERRA-2) and cirrus band time series provided by Landsat 8.

### cloudSEN12

CloudSEN12 is a globally spatio-temporal distributed dataset for cloud and cloud shadow semantic understanding that consists of 49,400 image patches (IP) that are evenly spread throughout all continents except Antarctica (Figure X). Each IP has an average size of 5090 x 5090 meters and contains data from Sentinel-2 optical levels 1C and 2A, Sentinel-1 Synthetic Aperture Radar (SAR), digital elevation model, surface water occurrence, land cover classes, cloud masking results from eight different algorithms and hand-crafted labeling data created using an active learning system \cite{francis_alistair_2020_4172871}. cloudSEN12 offers three different manual annotation types in order to support different deep learning strategies: (i) 10,000 IPs with high-quality pixel-level annotation, (ii) 10,000 IPs with scribble annotation, and (iii) 29,250 unlabeled IPs. Only high-quality IPs are used in this study because of the risk of bias due scene incompleteness in scribble annotation. A detailed description of the CloudSEN12 dataset is given in chapter one.

### Sen2Cor

Sentinel 2 Correction (\cite{Louis2016}) is a mono-temporal image processor designed for
scene classification and atmospheric correction of Sentinel-2 Level 1C input data. Sen2Cor version 2.8 is the version used in the Sentinel-2 ground segment with L2A processing baseline version 02.12. This processing baseline is the most recurrent version in cloudSEN12 (90% IPs). Sen2Cor (Figure X) uses a series of spectral reflectance thresholds, ratios, and indices based on bands 1–5, 8, and 10–12 to compute cloud and snow probabilities for each pixel. Besides, it includes a cloud shadow and cirrus detection algorithm. The cloud shadows are estimated by multiplying two probability layers: (1) a geometric probability layer constructed from the 
final thick cloud mask, sun position, and cloud height distribution, and (2) radiometric probability layer created from a Kohonen map to detect dark areas. On the other hand, cirrus probabilities are calculated simply by threshold band 10 (1.375 µm). Finally, a series of additional steps to improve the quality of the classification are automatically triggered using a priori information: digital elevation model (DEM) information, ESA CCI Water Bodies Map v4.0 (Lamarche et al., 2017), ESA CCI Land Cover Map v.2.0.7 (2015) and a snow climatology. In this study, SCL classes 8, 9 and 10 were used for cloud, class 3 for cloud shadow and the remaining SCL classes for non-cloud.

### Cloud type ocurrence 
  
The cloud type ocurrence (CTO) are derived from the CloudSat cloud profiling radar (CPR). This sensor permited for the first time to see cloud vertical structure (Stephens et al. 2008). ClouSat is part from Afternoon Constellation, or A-Train, at a frequency of 94 GHz and an altitude of about 700 km. Since 2011, it only produce daytime-only measurements due to battery malfunction, and in February 2018, the spacecraft systems moved to a lower orbit (C-train) to reduce the risk of collision with the other A-train spacecraft. The track of the satellite overpasses the same location every 16 days and provides a resolution of 1.4 km in cross-track and 1.8 km in along-track. Using the vertical profiles of clouds and precipitation, create an algorithms (\cite{}) to classify clouds according to the Cloud Climatology Project (ISCCP) approach: cumulus (Cu), stratocumulus (Sc), stratus (St), alto- cumulus (Ac), altostratus (As), nimbostratus (Ns), cirrus/ cirrostratus, or deep convective clouds. This information is storage in the 2B-CLDCLASS product. Particularly, in this study, we make use of the 3S-RMCP product of CloudSat level 3 observations. This product collocated 2B-CLDCLASS measurements in a 2.5°x2.5° grid. Based on this dataset, we constructed cloud type occurrence at 1° spatial
resolution. The TPR data used corresponds to the 2007–2016 period, the cloud type ocurrence were smoothed from 2.5° to 1° using cubic spline interpolation. We aggregathed the ISCCP classification into three classes accordin to the table x.


### MODIS


## Methodology
<!---
Problem statement
-->

The aim is to create a model that predict cloud masking error in a 1° x 1° worldwide grid given a $d-$dimensional training set of $n$ samples and real-valued targets such that $x_i\; and \; y_i \in \rm^{d}, \forall_i \; \epsilon \; \{1, ..., n\}$. In our regression problem setup, we define $n$ a set of 10000 independent IPs refered to the high-quality cloudSEN12 dataset with 20 static predictors: latitude, longitude, land use, cloud cover, elevation, cloud frequency, intra-annual variability, cloud type and sun and satellite position. We propose the use of a deep kernel learning (DKL) regression method based in the combination of artificial neural networks (ANN) and a gaussian processes (GP). While ANN captures the non-stationary and hierarchical structure, the flexibility of GP yield characterized by means of a non-parametric modelling, but also an estimation of their uncertainty. A general introduction to GP can be found in Rasmussen and Williams (2006). In the following we briefly review the standard GP, DKL, and the strategy followed to makes cloud error predictions at worldwide. 

### Gaussian process regresion

GPs assume a prior distribution of functions over the $\mathrm{COT}_{k}$ observations y.

\begin{equation}
    \begin{aligned}
        f(\mathbf{x}) & \sim 
            \mathcal{G}_{y}\left(
                m(\mathbf{x}), 
                k\left(\mathbf{x}, \mathbf{x}^{\prime}\right)\right
            ) \\
        y &=f(\mathbf{x})+\epsilon, \quad 
        \epsilon \sim \mathcal{N}\left(0, \sigma^{2}\right)
    \end{aligned} \label{eq:6}
\end{equation}

where, $\mathbf{x} \in \mathbb{R}^{d}$ is a feature vector, $y \in \mathbb{R}$ is observation, and $\epsilon$ is noise in observations with variance $\sigma^{2} . m(\mathbf{x}): \mathbb{R}^{d} \rightarrow \mathbb{R}$ is the prior mean function and $k\left(\mathbf{x}, \mathbf{x}^{\prime}\right): \mathbb{R}^{d} \times \mathbb{R}^{d} \rightarrow \mathbb{R}$ is the prior covariance function. In practice, we assume constant mean function without loss of generality. A well-known covariance function (kernel) is Radial Basis Function.

\begin{equation}
k_{RBF}\left(\mathbf{x}, \mathbf{x}^{\prime}\right) = 
        \sigma_{f}^{2} 
        \exp \left(
                \frac{
                        -\left\|\mathbf{x}-\mathbf{x}^{\prime}\right\|_{2}^{2}
                }{
                        2 \ell^{2}
                }\right
             ) \label{eq:7}
\end{equation}

Where $\sigma_{f}^{2}$ is kernel variance and $\ell$ is length scale. In the current setting, $\boldsymbol{\theta}=\left\langle\sigma_{f}, \sigma, \ell\right\rangle$ are the model hyperparameters. GP hyperparameters are learned during the training process. The negative log marginal likelihood $\mathcal{L}(\theta)$ is minimized with respect to training data points $\left(X_{n}, \mathbf{y}_{n}\right)$ to optimize the hyperparameters.

\begin{equation}
\mathcal{L}(\boldsymbol{\theta}) = \frac{1}{2}\left
    [
        \mathbf{y}^{T} K_{y}^{-1} \mathbf{y} +
        \log \left|K_{y}\right| +
        n\log(2\pi)\right
    ] \label{eq:8}
\end{equation}

Where $K_{y}=k\left(X_{n}, X_{n}\right)+\sigma^{2} I_{n}$. Post training, predictive distribution of observations for test points $X_{t}$ is given as

\begin{equation}
\mathbf{f}^{*} \sim \mathcal{N}\left(
    K^{* T} K_{y}^{-1} \mathbf{y}, K^{* *}-K^{* T} K_{y}^{-1} K^{*}
    \right
) \label{eq:9}
\end{equation}

where $K^{*}$ is $n \times t$ covariance matrix between train and test points and $K^{* *}$ is $t \times t$ covariance matrix among test points.

### Deep kernel learning

In addition to sparse GP, moved one step further and proposed to embed deep 
neural networks (DNNs) with GPs to learn more fexible representations. Te kernel
function transforms $k(x_i, x_j|\theta)$ to $k(g(x_i,w), g(x_j,w)|\theta, w)$, 
where $\theta$ are the kernel hyperparameters, $g(.)$ ) is a non-linear DNN, 
and $w$ are the parametrized weights of the network. Terefore, the DNN acts as 
a feature extractor to represent samples as latent vectors, and GPs can make 
inferences based on the learned latent features.

\begin{figure}[!h]
	\centering
	\includegraphics[width=1\linewidth]{figures/chapter02/figure02.png}
	\caption{Number of hand-crafted pixel annotations between different cloud detection datasets. All the labeled pixels in the CloudSEN12 no-annotation group come from cloud-free IPs.}
	\label{fig:figure02}
\end{figure}

### Model set-up and training

### Model metrics

### Model predictions

## Experimental results


## Discussion

dsada 

## Conclusion

dsada 